{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-10-10T19:13:24.028Z",
          "iopub.execute_input": "2020-10-10T19:13:24.032Z",
          "iopub.status.idle": "2020-10-10T19:13:24.041Z",
          "shell.execute_reply": "2020-10-10T19:13:24.046Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ParsePath(paths):\n",
        "    good = []\n",
        "    bad = []\n",
        "    for path in paths:\n",
        "        path_2 = path.split('/')\n",
        "        if int(path_2[2])%2 == 1:\n",
        "            if '_main' not in path_2[-1]:\n",
        "                bad.append(path)\n",
        "        else:\n",
        "            good.append(path)\n",
        "    return bad, good"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-10-10T19:13:27.492Z",
          "iopub.execute_input": "2020-10-10T19:13:27.496Z",
          "iopub.status.idle": "2020-10-10T19:13:27.502Z",
          "shell.execute_reply": "2020-10-10T19:13:27.505Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = open('index.txt', 'r').read().split('\\n')[:-1]\n",
        "bad = ParsePath(file_list)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-10-10T19:13:32.534Z",
          "iopub.execute_input": "2020-10-10T19:13:32.537Z",
          "iopub.status.idle": "2020-10-10T19:13:32.543Z",
          "shell.execute_reply": "2020-10-10T19:13:32.547Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning Functions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def findline(lines, target_string, num_line = 0):\n",
        "    # locate all lines that contains a keyword \"target_string\", recursively.\n",
        "    if num_line == len(lines):\n",
        "        return -1\n",
        "    if target_string in lines[num_line]:\n",
        "        return num_line\n",
        "    else:\n",
        "        return findline(lines, target_string, num_line + 1)\n",
        "    \n",
        "def FindAllFunctions(lines, file_name, function_starts = [], func_ns = [], func_number = 1, num_line = 0):\n",
        "    #Recursively find all functions in the file\n",
        "    if num_line == len(lines) - 1:\n",
        "        return function_starts, func_ns\n",
        "    else:\n",
        "        num_line += 1\n",
        "        func_n = format(func_number, '03d')\n",
        "        if ' ' + file_name + '_' + func_n + ' (' in lines[num_line] or ' ' + file_name + '_' + func_n + '(' in lines[num_line]:\n",
        "            function_starts.append(num_line)\n",
        "            func_ns.append(func_n)\n",
        "            func_number += 1\n",
        "        return FindAllFunctions(lines, file_name, function_starts, func_ns, func_number, num_line)\n",
        "    \n",
        "def FindCommentBlocks(lines, comment_starts = [], comment_ends = [], num_line = 0):\n",
        "    if num_line == len(lines) - 1:\n",
        "        return comment_starts, comment_ends\n",
        "    else:\n",
        "        num_line += 1\n",
        "        if lines[num_line] == '/*':\n",
        "            comment_starts.append(num_line)\n",
        "        elif lines[num_line] == '*/':\n",
        "            comment_ends.append(num_line)\n",
        "        return FindCommentBlocks(lines, comment_starts, comment_ends, num_line)\n",
        "\n",
        "def deletecomment(string):\n",
        "    if '/*' not in string:\n",
        "        return string\n",
        "    comment_start = string.find('/*')\n",
        "    comment_end = string.find('*/')\n",
        "    return deletecomment(string[:comment_start] + string[comment_end + 2:])\n",
        "\n",
        "def cleanupfunction(function):\n",
        "    #Delete redundant spaces and tabs\n",
        "    function0 = [line.lstrip().rstrip() for line in function]\n",
        "    function = []\n",
        "    \n",
        "    #Delete compiler instruction lines\n",
        "    for line in function0:\n",
        "        if len(line) > 0:\n",
        "            if line[0] != '#':\n",
        "                function.append(line)\n",
        "    function = ''.join(function)\n",
        "    signs = ['=', '+', '-', '/', '!=', '==', '<<', '>>', ',', ')', '(', '}', '{']\n",
        "    \n",
        "    # Delete redundant spaces before and after a syntax\n",
        "    for sign in signs:\n",
        "        function = function.replace(' ' + sign, sign)\n",
        "        function = function.replace(sign + ' ', sign)\n",
        "    function = function.replace('if ', 'if')\n",
        "    return function\n",
        "    \n",
        "def ParseFile(file_name, good_or_bad):\n",
        "    file = open(file_name, 'r')\n",
        "    f = file.read().split('\\n')\n",
        "    f = [line.lstrip().rstrip() for line in f]\n",
        "    file.close()\n",
        "    f_name = file_name.split('/')[-1].split('.')[0]\n",
        "    function_starts, func_ns = FindAllFunctions(f, f_name, function_starts = [], func_ns = [], func_number = 1, num_line = 0)\n",
        "    comment_starts, comment_ends = FindCommentBlocks(f, comment_starts = [], comment_ends = [], num_line = 0)\n",
        "    comment_starts = comment_starts[2:]\n",
        "    comment_ends = comment_ends[1: -1]\n",
        "    \n",
        "    function_list = []\n",
        "    \n",
        "    for i in range(len(function_starts)):\n",
        "        function = f[comment_ends[i]+1:comment_starts[i]]\n",
        "        function = cleanupfunction(function)\n",
        "        function = deletecomment(function)\n",
        "        function = function.replace(f_name + '_', '')\n",
        "        if good_or_bad:\n",
        "            function = function.replace(func_ns[i], 'good')\n",
        "        else:\n",
        "            function = function.replace(func_ns[i], 'bad')\n",
        "        \n",
        "        while '  ' in function:\n",
        "            function = function.replace('  ', ' ')\n",
        "        function_list.append(function)\n",
        "        \n",
        "    return function_list, f_name"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-10-10T19:13:52.923Z",
          "iopub.execute_input": "2020-10-10T19:13:52.927Z",
          "iopub.status.idle": "2020-10-10T19:13:52.932Z",
          "shell.execute_reply": "2020-10-10T19:13:52.936Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsing code instance into list of syntax."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def toWordLevel(instance):\n",
        "    instance = ' '.join(instance.split())\n",
        "    parser_list_lv1 = ['==', '!=', '&&', '||', '<=', '>=', '>>', '<<']\n",
        "    parser_list_lv2 = ['!', ';', '=', '+', '-', '&', '%', '*', ':', '.', '|', '/', '(', ')', '{', '}', '[', ']', '<', '>', '\\'', '\\\"', ',', '_', ' ']\n",
        "    \n",
        "    parselv1 = []\n",
        "    while len(instance) > 2:\n",
        "        i = 0\n",
        "        while True:\n",
        "            if instance[i:i+2] in parser_list_lv1:\n",
        "                if i != 0:\n",
        "                    parselv1.append(instance[:i])\n",
        "                parselv1.append(instance[i:i+2])\n",
        "                instance = instance[i+2:]\n",
        "                break\n",
        "            if i == len(instance):\n",
        "                parselv1.append(instance)\n",
        "                instance = ''\n",
        "                break\n",
        "            i += 1\n",
        "    parselv2 = []\n",
        "    for st in parselv1:\n",
        "        if st not in parser_list_lv1:\n",
        "            while len(st) > 0:\n",
        "                i = 0\n",
        "                while True:\n",
        "                    if i == len(st):\n",
        "                        parselv2.append(st)\n",
        "                        st = ''\n",
        "                        break\n",
        "                    if st[i] in parser_list_lv2:\n",
        "                        if i != 0:\n",
        "                            parselv2.append(st[:i])\n",
        "                        parselv2.append(st[i])\n",
        "                        st = st[i+1:]\n",
        "                        break\n",
        "                    i += 1\n",
        "        else:\n",
        "            parselv2.append(st)\n",
        "    return parselv2"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-10-10T19:17:25.657Z",
          "iopub.execute_input": "2020-10-10T19:17:25.661Z",
          "iopub.status.idle": "2020-10-10T19:17:25.668Z",
          "shell.execute_reply": "2020-10-10T19:17:25.670Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = open('data.txt', 'w+')\n",
        "src_train = open('src_train.txt', 'w+')\n",
        "src_test = open('src_test.txt', 'w+')\n",
        "src_val = open('src_val.txt', 'w+')\n",
        "count = 0\n",
        "\n",
        "for i in range(len(bad)):\n",
        "    #array 'bad' contains the function names \n",
        "    bad_fs, _= ParseFile(bad[i], good_or_bad = False)\n",
        "    for j in range(len(bad_fs)):\n",
        "        ins = toWordLevel(bad_fs[j])\n",
        "        if len(ins) < 400:\n",
        "            rand = random.random()\n",
        "            count += 1\n",
        "            print(format(i, '03d'), bad_fs[j], file = data_file)\n",
        "            if rand < 0.80:\n",
        "                print(format(i, '03d'), bad_fs[j], file = src_train)\n",
        "            elif rand >=0.80 and rand < 0.90: \n",
        "                print(format(i, '03d'), bad_fs[j], file = src_test)\n",
        "            else:\n",
        "                print(format(i, '03d'), bad_fs[j], file = src_val)\n",
        "print(count)\n",
        "data_file.close()\n",
        "src_train.close()\n",
        "src_test.close()\n",
        "src_val.close()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "580\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-10-10T19:17:27.725Z",
          "iopub.execute_input": "2020-10-10T19:17:27.728Z",
          "iopub.status.idle": "2020-10-10T19:17:27.900Z",
          "shell.execute_reply": "2020-10-10T19:17:27.907Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since This is transfer Learning, we need to include new vocabulary that did not appear in the old dataset."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total = open('data.txt', 'r').read().split('\\n')[:-1]\n",
        "total = [total[i][4:] for i in range(len(total))]\n",
        "vocab = {}\n",
        "vocab_file = open('vocab_new.txt', 'w+')\n",
        "for ins in total:\n",
        "    lst = toWordLevel(ins)\n",
        "    for word in lst:\n",
        "        if word in vocab:\n",
        "            vocab[word] += 1\n",
        "        else:\n",
        "            vocab[word] = 1\n",
        "for word in vocab.keys():\n",
        "    print(word, file = vocab_file)\n",
        "vocab_file.close()\n",
        "vocab_old = open('vocab_old.txt', 'r').read().split('\\n')\n",
        "vocab_new = open('vocab_new.txt', 'r').read().split()\n",
        "vocab_tt = open('vocab_combined.txt', 'w+')\n",
        "vocab_total = [word for word in vocab_old]\n",
        "\n",
        "for word in vocab_new:\n",
        "    if word not in vocab_old:\n",
        "        vocab_total.append(word)\n",
        "for word in vocab_total:\n",
        "    print(word, file = vocab_tt)\n",
        "vocab_tt.close()"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-10-10T19:17:30.314Z",
          "iopub.execute_input": "2020-10-10T19:17:30.319Z",
          "iopub.status.idle": "2020-10-10T19:17:30.389Z",
          "shell.execute_reply": "2020-10-10T19:17:30.392Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.25.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}